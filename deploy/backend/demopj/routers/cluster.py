# routers/cluster.py
from fastapi import APIRouter, Depends, BackgroundTasks, HTTPException
from sqlalchemy.ext.asyncio import AsyncSession
from demopj.database import get_session
from demopj.models import DataPoint, ClusterJob, Cluster, ClusterMember
from demopj.schemas import ClusterRequest, ClusterJobOut, ClusterResult
from sklearn.cluster import KMeans            # pip install scikit-learn
import numpy as np
from uuid import UUID
import datetime
import select
from demopj.database import SYNC_DATABASE_URL  # â† ìƒˆ ìƒìˆ˜ import


router = APIRouter(prefix="/analyze", tags=["analyze"])

@router.get("/job/{job_id}", response_model=ClusterJobOut)
async def get_job(job_id: UUID, db: AsyncSession = Depends(get_session)):
    job = await db.get(ClusterJob, job_id)
    if not job: raise HTTPException(404)
    return job

@router.get("/result/{job_id}", response_model=list[ClusterResult])
async def get_result(job_id: UUID, db: AsyncSession = Depends(get_session)):
    job = await db.get(ClusterJob, job_id)
    if not job or job.status != "done":
        raise HTTPException(404, "Job not finished or missing")
    res = await db.execute(
        select(Cluster).where(Cluster.job_id == job_id).order_by(Cluster.label)
    )
    clusters = res.scalars().all()
    output = []
    for c in clusters:
        mem_ids = [m.datapoint_id for m in c.members]
        output.append(
            ClusterResult(label=c.label,
                          centroid=c.centroid,
                          members=mem_ids)
        )
    return output


@router.post("/cluster", response_model=ClusterJobOut, status_code=202)
@router.post("/cluster", response_model=ClusterJobOut, status_code=202)
async def create_cluster_job(
    payload: ClusterRequest,  # í•„ìš”ì‹œ schemaì—ì„œ datapoint_ids í•„ë“œ ì‚­ì œ
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_session),
):
    job = ClusterJob(n_clusters=payload.n_clusters, status="pending")
    db.add(job)
    await db.commit()
    await db.refresh(job)
    
    # ì´ì œëŠ” ê²Œì‹œê¸€, ëŒ“ê¸€ì—ì„œ ìë™ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ ë¶„ì„
    background_tasks.add_task(
        run_clustering, job.id, SYNC_DATABASE_URL
    )
    return job
  

async def run_clustering(job_id: UUID, db_url: str):
    from sqlalchemy import select, create_engine
    from sqlalchemy.orm import Session
    from sklearn.cluster import KMeans
    from demopj.models import Post
    import datetime
    import numpy as np

    engine = create_engine(db_url, future=True)

    with Session(engine) as s:
        job = s.get(ClusterJob, job_id)
        job.status, job.started_at = "running", datetime.datetime.utcnow()
        s.commit()

        # ğŸ“Œ 1. ê²Œì‹œê¸€ê³¼ ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸°
        posts = s.execute(select(Post)).scalars().all()
        if not posts:
            job.status = "failed"
            s.commit()
            return

        raw_texts = [
            f"{post.title} {post.content} {' '.join(c.content for c in post.comments)}"
            for post in posts
        ]

        # ğŸ“Œ 2. í…ìŠ¤íŠ¸ â†’ ë²¡í„° ë³€í™˜ (ì„ë² ë”©)
        vectors = [simple_text_embedding(text) for text in raw_texts]

        # ğŸ“Œ 3. K-Means ìˆ˜í–‰
        km = KMeans(n_clusters=job.n_clusters, random_state=0)
        km.fit(vectors)

        # ğŸ“Œ 4. í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ì €ì¥
        for lbl in range(job.n_clusters):
            cl = Cluster(
                job_id=job.id,
                label=lbl,
                centroid=km.cluster_centers_[lbl].tolist()
            )
            s.add(cl)
            s.flush()  # id í™•ë³´

            for post, vec, dist in zip(posts, vectors, km.transform(vectors)[:, lbl]):
                if km.labels_[posts.index(post)] == lbl:
                    s.add(ClusterMember(
                        cluster_id=cl.id,
                        datapoint_id=post.id,  # ì—¬ê¸°ì„  post_idë¥¼ ì €ì¥ (datapoint_idë¥¼ ì¬í™œìš©)
                        distance=float(dist)
                    ))

        job.status = "done"
        job.finished_at = datetime.datetime.utcnow()
        s.commit()

def simple_text_embedding(text: str) -> list[float]:
    """
    ì´ˆê°„ë‹¨ í…ìŠ¤íŠ¸ ì„ë² ë”© í•¨ìˆ˜ (ì˜ˆì‹œìš©).
    ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œëŠ” Sentence-BERTë‚˜ OpenAI ì„ë² ë”© ë“± ê°•ë ¥í•œ ì„ë² ë”©ì„ ì“°ì„¸ìš”.
    """
    return [len(text), sum(ord(c) for c in text) % 1000]


def flatten(raw: dict) -> list[float]:
    """ğŸ‘¶ğŸ» ì˜ˆì‹œ ë³€í™˜ê¸°: ìˆ«ìë§Œ ë½‘ì•„ ì •ë ¬. í•„ìš” ì‹œ ì—¬ê¸° ë§ì¶¤ ìˆ˜ì •."""
    return [v for _, v in sorted(raw.items()) if isinstance(v, (int, float))]
